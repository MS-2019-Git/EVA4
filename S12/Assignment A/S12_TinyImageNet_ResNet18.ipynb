{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S12_TinyImageNet_ResNet18.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMM9SJyCUIAz7rK9kV6cL/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohuaSinha/EVA4/blob/master/S12/Assignment%20A/S12_TinyImageNet_ResNet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83u7-gAZbUlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ffb3de7a-1b58-4a0e-dfd9-a056effdeb15"
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiQ_U40ubaFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "cd8d3a25-c9d0-4824-ae99-cdc58504fc23"
      },
      "source": [
        "%cd \"//content/gdrive/My Drive/Colab Notebooks/EVA4/S12\"\n",
        "import sys\n",
        "workingdir = '/content/gdrive/My Drive/Colab Notebooks/EVA4/S12'\n",
        "sys.path.append(workingdir)\n",
        "\n",
        "!unzip -q \"/content/gdrive/My Drive/Colab Notebooks/EVA4/S12/tiny-imagenet-200.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls-ltr"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/EVA4/S12\n",
            "total 242290\n",
            "drwx------ 5 root root      4096 Feb  9  2015 \u001b[0m\u001b[01;34mtiny-imagenet-200\u001b[0m/\n",
            "-rw------- 1 root root 248100043 Apr 15 14:18 tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPo0YPxxZB5v",
        "colab_type": "text"
      },
      "source": [
        "# **Extract test and training data from Tiny ImageNet DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWCScrM8YpAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "a23096ae-7d77-49b9-e7bd-2dfd2cd6c995"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import scipy.ndimage as nd\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "path = 'tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)),pilmode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread( path + 'val/images/{}'.format(img_name) ,pilmode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "  \n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting loading data\n",
            "finished loading data, in 237.36653304100037 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28hoI_Nrq6fz",
        "colab_type": "text"
      },
      "source": [
        "# **Shuffle training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZsoTaW-q-hV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "0aced7c3-623d-4edd-aaa2-78d01032f2af"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "def shuffle_data(train_data, train_labels):\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split=int(np.floor(0.3*num_train))\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "    train_idx,test_idx=indices[split:],indices[:split]\n",
        "\n",
        "    train_sampler=SubsetRandomSampler(train_idx)\n",
        "    test_sampler=SubsetRandomSampler(test_idx)\n",
        "\n",
        "    normalize = transforms.Normalize(mean = [0.44785526394844055, 0.41693055629730225, 0.36942949891090393],\n",
        "                                     std = [0.2928885519504547, 0.28230994939804077, 0.2889912724494934])\n",
        "    train_dataset = datasets.ImageFolder('tiny-imagenet-200/train',\n",
        "        transforms.Compose([\n",
        "            transforms.RandomCrop(64, padding = 4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    #train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle = True, num_workers = 4, pin_memory = False)\n",
        "\n",
        "    DataLoader(train_dataset, batch_size = 1, shuffle = False, num_workers = 0, pin_memory = False)\n",
        "    trainloader= torch.utils.data.DataLoader(train_data,sampler=train_sampler,batch_size=64)\n",
        "    testloader=torch.utils.data.DataLoader(train_data,sampler=test_sampler,batch_size=64)\n",
        "\n",
        "    #return train_data[train_idx], train_labels[train_idx],test_data[test_idx], test_labels[test_idx]\n",
        "    return trainloader,testloader\n",
        "  \n",
        "trainloader,testloader = shuffle_data(train_data, train_labels)\n",
        "print(len(train_data))\n",
        "print(train_data.shape)\n",
        "print(testloader.size)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n",
            "(100000, 64, 64, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-be524f9d25d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'size'"
          ]
        }
      ]
    }
  ]
}